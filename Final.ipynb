{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mad100141/final15388/blob/master/Final.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YBC1fA8VNirF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Real Estate Value Estimation"
      ]
    },
    {
      "metadata": {
        "id": "Zvc88TatNt6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our goal for this project is to determine if the exterior appearance of a building has predictive power in determining the real estate value of a home. \n",
        "\n",
        "We started with Boston property assessment data, which contains many features which can be used to indicate the value of a home. To get an accurate picture of real market value, we scraped sale prices from zillow for a subset of the properties. We scraped Google Street View images for these properties and extracted 25 features which describe qualities of the home and added those features as predictor variables."
      ]
    },
    {
      "metadata": {
        "id": "Pg_SPzEJNCOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Boston Data\n",
        "\n",
        "Our Boston Data is acquired from data.boston.gov. The Boston Assessing Department, charged with  determining the value of property in Boston for the purposes of taxation, has helpfully released their information into the public domain. From their assessments of several different property types we focus on residential properties to acquire information regarding address, property value, building style, exterior and interior condition and several other indicators of value. A full list resides [here](https://data.boston.gov/dataset/property-assessment/resource/b8e32ddf-671f-4a35-b99f-c060bae958e5). We decided to focus on assessments in 2018, acquired [here](https://data.boston.gov/dataset/property-assessment/resource/fd351943-c2c6-4630-992d-3f895360febd), to apply our analysis on the most up to date information regarding Boston residential property."
      ]
    },
    {
      "metadata": {
        "id": "qZjUW8jOT0il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "boston = pd.read_csv(\"ast2018full.csv\", dtype = {15:str,60:str,63:str})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIoKAHIsY5PM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1aVNNvbRZA07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston.LU = boston.LU.astype(\"category\")\n",
        "boston.R_BLDG_STYL = boston.R_BLDG_STYL.astype(\"category\")\n",
        "\n",
        "residential_category = [\"A\",\"CD\",\"R1\",\"R2\",\"R3\",\"R4\",\"RL\"]\n",
        "residential_bool = [True if x in residential_category else False for x in boston.LU]\n",
        "residential = boston[residential_bool]\n",
        "\n",
        "residential.dropna(subset = [\"R_BLDG_STYL\"], inplace = True)\n",
        "\n",
        "residential.drop(labels = ['MAIL_ADDRESSEE', 'MAIL_ADDRESS', 'MAIL CS', \n",
        "                           'MAIL_ZIPCODE','PID', 'CM_ID', 'GIS_ID','OWNER',\n",
        "                           'S_BLDG_STYL', 'S_UNIT_RES', 'S_UNIT_COM',\n",
        "                           'S_UNIT_RC', 'S_EXT_FIN', 'S_EXT_CND'], \n",
        "                 axis = 1, inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6oE1a_SdXsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential = residential.dropna(axis = 1, how = \"all\") #removing columns with only NA's\n",
        "residential = residential.dropna(axis = 0, how = \"all\") #removing rows with only NA's, there's none"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0MkfAWtddC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential[\"ST_ADDRESS\"] = residential['ST_NUM'] + \" \" + residential['ST_NAME'] + \" \" + residential['ST_NAME_SUF']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ExkAZJu1dfsP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential = residential.drop_duplicates(\"ST_ADDRESS\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_Ex6Zp6M6qG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Scraping Zillow Data\n",
        "\n",
        "For scraping our Zillow response variables we used Chris Muir's Zillow's Scraper. He uses Python and Selenium to current home listings from given search terms. Acquired [here](https://github.com/ChrisMuir/Zillow) we go through the zillow_runfile.py and change the input search area to the Boston Zipcodes we want to scrape through.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qXQNudO8iSFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zillow = pd.read_csv(\"../Zillow/2018-05-07_210318.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRHi7gqvngUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we can combine our data from Boston and Zillow we run through several cleaning measures regarding unrealistic Sold Prices, NA's in crucial predictor columns, inconsistent address formatting, and odd price inputs. After fixing these we combine the Boston and Zillow data sets on the addresses that appear in both and add in the Sold Prices and Addresses of those properties that we have full information for. We did these things half manually through Excel and some Python commands and as a result recreating the full data cleaning process is somewhat difficult. Our final CSV file containing  around 2000~ properties is below."
      ]
    },
    {
      "metadata": {
        "id": "PuaN48ndiSfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential_zillow = pd.read_csv(\"residential_zillow.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSoHJTJ6Lm0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scraping Street View Data\n",
        "Using the Google Street View API we acquire images from all the properties in our combined data. Scraping the images for our properties took around 3 minutes but we then had to manually parse through all images and remove those that were invalid where invalid is defined as the property being occluded by trees, trucks, or otherwise bad image captures due to angle and height."
      ]
    },
    {
      "metadata": {
        "id": "qzbD2e7oLm0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib, os\n",
        "count = 0\n",
        "myloc = r\"streetView\" #replace with your own location\n",
        "key = \"&key=AIzaSyBYG7d1Nml_Z6emFfRdqSnJj6065HBFekY\"\n",
        "def GetStreet(Add,SaveLoc, count):\n",
        "    base = \"https://maps.googleapis.com/maps/api/streetview?size=640x480&fov=90&location=\"\n",
        "    MyUrl = base + urllib.parse.quote_plus(Add) + key  #added url encoding\n",
        "    fi = str(count) + \".jpg\"\n",
        "    urllib.request.urlretrieve(MyUrl, os.path.join(SaveLoc,fi))\n",
        "    count += 1\n",
        "\n",
        "for location in names:\n",
        "    GetStreet(Add=location,SaveLoc=myloc, count=count)\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ng315NFdqvkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Example Output\n",
        "im = Image.open(\"streetView/0.jpg\")\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDiaMJ-8Lm0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('streetViewX.pickle', 'rb') as handle:\n",
        "    X_SV = pickle.load(handle)\n",
        "with open('streetViewy.pickle', 'rb') as handle:\n",
        "    y_SV = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2oGB4w7s0gz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Architectural Style Dataset"
      ]
    },
    {
      "metadata": {
        "id": "fCHfeP4ks4_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "gbUOoSIZSiQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Processing Images"
      ]
    },
    {
      "metadata": {
        "id": "HiibgUPdSuNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "import keras.preprocessing.image as KerasImage\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROdh_6kPjGOo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We used the VGG19 model to process images.  The model can be downloaded through Keras with the weights pretrained on the imagenet dataset. You can read more about the model [here](https://arxiv.org/pdf/1409.1556.pdf). \n",
        "\n",
        "The model was originally trained to classify objects like cats and dogs, which isn't the task on hand. However, we can still use the model to process our images and output useful vectors.\n",
        "\n",
        "We can modify the model relatively easily with Keras, which allows us to strip the classifying layers from the model and use a custom input image vector to "
      ]
    },
    {
      "metadata": {
        "id": "seYbwDxVSydG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = VGG19(include_top=False, input_shape=(800,600,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C90A7WXqlXbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The default model outputs a four dimensional array, so we'll have to flatten that into a 1d vector in order to properly interface with the outputs later on"
      ]
    },
    {
      "metadata": {
        "id": "rLQABNHjV9UG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = model.get_layer('block5_pool').output\n",
        "output = keras.layers.Flatten()(output)\n",
        "model = keras.models.Model(model.input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTQIVK1vng5M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our architectural style dataset was organized such that each unique style classification had its own folder containing the images which belonged to that class. \n",
        "\n",
        "The following code traverses the parent folder, pushes each image through the VGG model, and labels the resulting vectors with the appropriate class."
      ]
    },
    {
      "metadata": {
        "id": "mHBK0mMCWcKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open the specified folder and get all the subdirectories\n",
        "dname = \"D:\\\\DataScience\\\\arcDataset\"\n",
        "sdnames = os.listdir(dname)\n",
        "\n",
        "# Set up dummy arrays to hold the processed features and labels \n",
        "y = np.array([-1])\n",
        "X = np.array([i for i in range(230400)])\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(len(sdnames):\n",
        "    sdname = sdnames[i] + '/'\n",
        "               \n",
        "    # Ignore non-directory files \n",
        "    try: fnames = os.listdir(dname + sdname)\n",
        "    except: continue\n",
        "               \n",
        "    for j in range(len(fnames)):\n",
        "        fname = dname + sdname + fnames[j]\n",
        "        \n",
        "        # Ignore non-image files\n",
        "        try: im = KerasImage.load_img(fname, target_size=(800,600))\n",
        "        except: continue\n",
        "               \n",
        "        # Print out a message to show progression \n",
        "        count += 1\n",
        "        sys.stdout.write(\"\\rsdir: \" + str(i) + \" im: \" + str(j))\n",
        "        sys.stdout.flush()\n",
        "               \n",
        "        # Format image properly\n",
        "        im = KerasImage.img_to_array(im)\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        \n",
        "        # Push image through the model\n",
        "        im = preprocess_input(im)\n",
        "        im = model.predict(im)\n",
        "        \n",
        "        # Correct shape of output vector\n",
        "        im = np.squeeze(im)\n",
        "        \n",
        "        # Add vector to X and label to y\n",
        "        X = np.append(X, im, axis=0)\n",
        "        y = np.append(y, np.array([i]), axis=0)\n",
        "\n",
        "# Delete the placeholder vectors\n",
        "X = np.delete(X, range(230400), axis=0)\n",
        "y = np.delete(y, 0, axis=0)\n",
        "\n",
        "# Reshape the features               \n",
        "X = X.reshape(count, 230400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ma2OTEvvqUXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We went through a similar process for our street view images. The code is nearly identical, just with a few lines commented out because the data was unlabeled and because we did not need to traverse a file structure in the same way.\n",
        "\n",
        "We've omitted this code for the sake of brevity."
      ]
    },
    {
      "metadata": {
        "id": "tZLozmnssCC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "S-4jlV0ksikx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To turn these "
      ]
    },
    {
      "metadata": {
        "id": "Mfijp6UGLm0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import scipy.stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZScKE36NLm0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('arcDataX.pickle', 'rb') as handle:\n",
        "    X = pickle.load(handle)\n",
        "with open('arcDatay.pickle', 'rb') as handle:\n",
        "    y = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKO2xCaVLm0j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_arctr, X_arctest, y_arctr, y_arctest = train_test_split(X, y, test_size=0.3, random_state=5)\n",
        "X_arctest, X_arcval, y_arctest, y_arcval = train_test_split(X_arctest, y_arctest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_4Bv6I-Lm0m",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9ac05d3-d726-43b8-8b90-60cdbab89413"
      },
      "cell_type": "code",
      "source": [
        "model_arc = LR(random_state = 0, dual=False, max_iter=3000)\n",
        "model_arc.fit(X_arctr, y_arctr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=3000, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "metadata": {
        "id": "HDG0unXlLm0p",
        "colab_type": "code",
        "colab": {},
        "outputId": "36baf248-2000-4b3f-fac7-3050390bf509"
      },
      "cell_type": "code",
      "source": [
        "model_arc.score(X_arctest, y_arctest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.702928870292887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "metadata": {
        "id": "pnK6LZ30MAXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adding Features to Original Dataset"
      ]
    },
    {
      "metadata": {
        "id": "7r1Z1RlkLm0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"residential_zillow.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ix6fvrV0Lm01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#indexed with valid images\n",
        "df_final = data.iloc()[y_SV.astype(int)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fg3I8wAOLm04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_SVC = model_arc.predict_proba(X_SV)\n",
        "\n",
        "X_SVCdf = pd.DataFrame(data=X_SVC, index=y_SV);\n",
        "\n",
        "X_SVCdf.index = X_SVCdf.index.astype(int)\n",
        "\n",
        "df_final1 = pd.concat([df_final, X_SVCdf], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6aIozmiLm07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_final = df_final1['SALE_PRICE']\n",
        "\n",
        "X_final = df_final1.drop('SALE_PRICE', axis=1)\n",
        "X_final = X_final.drop(['ST_NUM', 'ST_NAME', 'ST_NAME_SUF', 'AV_LAND', 'AV_BLDG', 'AV_TOTAL', 'GROSS_TAX', 'ST_ADDRESS','PTYPE'], axis=1)\n",
        "\n",
        "X_final = pd.get_dummies(X_final, columns=['R_BLDG_STYL','LU','OWN_OCC','STRUCTURE_CLASS','R_ROOF_TYP','R_EXT_FIN','R_EXT_CND','R_BTH_STYLE','R_BTH_STYLE2','R_BTH_STYLE3','R_KITCH_STYLE','R_KITCH_STYLE2','R_KITCH_STYLE3','R_HEAT_TYP','R_AC','R_OVRALL_CND','R_INT_CND','R_INT_FIN','R_VIEW'])\n",
        "X_final = X_final.astype(np.float32).fillna(0)\n",
        "\n",
        "# X_final = X_final.reset_index().drop('index', axis=1)\n",
        "# y_final = y_final.reset_index().drop('index', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6yhtEZz7Lm0_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_final = X_final.drop('Unnamed: 0', axis=1).reset_index(drop=True)\n",
        "y_final = y_final.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFxbSiRhLm1A",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a328f64-77fb-4f35-8377-2624e5cd0a41"
      },
      "cell_type": "code",
      "source": [
        "X_final.assign(Value =y_final.squeeze()).apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)['Value']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ZIPCODE             0.079714\n",
              "LAND_SF             0.263169\n",
              "YR_BUILT            0.053118\n",
              "YR_REMOD            0.060519\n",
              "GROSS_AREA          0.301567\n",
              "LIVING_AREA         0.303270\n",
              "NUM_FLOORS          0.072153\n",
              "R_TOTAL_RMS        -0.009428\n",
              "R_BDRMS            -0.014479\n",
              "R_FULL_BTH          0.013468\n",
              "R_HALF_BTH          0.005019\n",
              "R_KITCH            -0.055054\n",
              "R_FPLACE            0.078625\n",
              "0                   0.371457\n",
              "1                   0.371457\n",
              "2                   0.371457\n",
              "3                   0.371457\n",
              "4                   0.371457\n",
              "5                   0.371457\n",
              "6                   0.371457\n",
              "7                   0.371457\n",
              "8                   0.371457\n",
              "9                   0.371457\n",
              "10                  0.371457\n",
              "11                  0.371457\n",
              "12                  0.371457\n",
              "13                  0.371457\n",
              "14                  0.371457\n",
              "15                  0.371457\n",
              "16                  0.371457\n",
              "                      ...   \n",
              "R_KITCH_STYLE3_N   -0.034522\n",
              "R_KITCH_STYLE3_S   -0.056608\n",
              "R_HEAT_TYP_E       -0.022175\n",
              "R_HEAT_TYP_F        0.013484\n",
              "R_HEAT_TYP_N       -0.019901\n",
              "R_HEAT_TYP_O       -0.024673\n",
              "R_HEAT_TYP_P       -0.002974\n",
              "R_HEAT_TYP_S       -0.035530\n",
              "R_HEAT_TYP_W       -0.004737\n",
              "R_AC_C              0.078809\n",
              "R_AC_D             -0.028873\n",
              "R_AC_N              0.072534\n",
              "R_OVRALL_CND_A      0.047183\n",
              "R_OVRALL_CND_E      0.070352\n",
              "R_OVRALL_CND_F      0.002341\n",
              "R_OVRALL_CND_G      0.027799\n",
              "R_OVRALL_CND_P     -0.009365\n",
              "R_INT_CND_A        -0.041118\n",
              "R_INT_CND_E         0.082973\n",
              "R_INT_CND_F         0.023095\n",
              "R_INT_CND_G        -0.009477\n",
              "R_INT_CND_P        -0.009365\n",
              "R_INT_FIN_E         0.100286\n",
              "R_INT_FIN_N         0.100286\n",
              "R_VIEW_A            0.001133\n",
              "R_VIEW_E            0.012223\n",
              "R_VIEW_F           -0.004389\n",
              "R_VIEW_G            0.014428\n",
              "R_VIEW_P           -0.034147\n",
              "Value               1.000000\n",
              "Name: Value, Length: 133, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "0-Z_AIO1Lm1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_finaltr, X_finaltest, y_finaltr, y_finaltest = train_test_split(X_final, y_final, test_size=0.3, random_state=5)\n",
        "X_finaltest, X_finalval, y_finaltest, y_finalval = train_test_split(X_finaltest, y_finaltest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LaYS6tEMdrd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-Validating Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "mW-Pi4-ELm1H",
        "colab_type": "code",
        "colab": {},
        "collapsed": true,
        "outputId": "90bbbfb3-9638-446c-dc88-636dd24cd2ae"
      },
      "cell_type": "code",
      "source": [
        "to_try = [2,3,1]\n",
        "numTrials = 3\n",
        "best = 0\n",
        "bestVal = 0\n",
        "for val in to_try: \n",
        "    score = 0\n",
        "    for i in range(numTrials):\n",
        "        GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                                    subsample=.99,alpha=.89)\n",
        "        GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
        "        curScore = GBR.score(X_finalval, y_finalval.squeeze())\n",
        "        score += curScore\n",
        "        print(\"testing \" + str(val) + \" - score: \" + str(curScore))\n",
        "    score /= 3\n",
        "    print(\"avg for \" + str(val) + \": \" + str(score))\n",
        "    if score > best: \n",
        "        best = score\n",
        "        bestVal = val\n",
        "print(\"best choice is: \" + str(bestVal))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing 2 - score: 0.563488374663454\n",
            "testing 2 - score: 0.5497977215495489\n",
            "testing 2 - score: 0.564611005381296\n",
            "avg for 2: 0.5592990338647663\n",
            "testing 3 - score: 0.550701541561935\n",
            "testing 3 - score: 0.5742114205959534\n",
            "testing 3 - score: 0.5532390351072125\n",
            "avg for 3: 0.559383999088367\n",
            "testing 1 - score: 0.5656458563598071\n",
            "testing 1 - score: 0.5625804955060273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-14230b3e6392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumTrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mGBR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quantile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finaltr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finaltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcurScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finalval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finalval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcurScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n\u001b[1;32m    797\u001b[0m                                              \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                              self.learning_rate, k=k)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m# add tree to ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, y_pred, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    247\u001b[0m             self._update_terminal_region(tree, masked_terminal_regions,\n\u001b[1;32m    248\u001b[0m                                          \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                          y_pred[:, k], sample_weight)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# update predictions (both in-bag and out-of-bag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_update_terminal_region\u001b[0;34m(self, tree, terminal_regions, leaf, X, y, residual, pred, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m                                 residual, pred, sample_weight):\n\u001b[1;32m    436\u001b[0m         \u001b[0mterminal_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_regions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         diff = (y.take(terminal_region, axis=0)\n\u001b[0m\u001b[1;32m    438\u001b[0m                 - pred.take(terminal_region, axis=0))\n\u001b[1;32m    439\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vgzUggUGLm1K",
        "colab_type": "code",
        "colab": {},
        "outputId": "8305d6b1-1d30-46bd-90eb-81b14f24d953"
      },
      "cell_type": "code",
      "source": [
        "GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                            subsample=.99,alpha=.89)\n",
        "GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
        "GBR.score(X_finalval, y_finalval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7901517153918347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "metadata": {
        "id": "EyxpCYbGLm1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_nSV = X_final.drop(labels=list(range(25)), axis=1)\n",
        "y_nSV = y_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ft9nHkjKLm1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_nSVtr, X_nSVtest, y_nSVtr, y_nSVtest = train_test_split(X_nSV, y_nSV, test_size=0.3, random_state=5)\n",
        "X_nSVtest, X_nSVval, y_nSVtest, y_nSVval = train_test_split(X_nSVtest, y_nSVtest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7XJ4aMxLm1W",
        "colab_type": "code",
        "colab": {},
        "outputId": "63a267c9-8b56-42b1-e337-e5887d602a9d"
      },
      "cell_type": "code",
      "source": [
        "GBRnSV = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                                    subsample=.99,alpha=.89)\n",
        "GBRnSV.fit(X_nSVtr, y_nSVtr)\n",
        "\n",
        "GBRnSV.score(X_nSVval, y_nSVval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36443930091932547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "v2RH2EauLm1Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a9098d5-bc9d-4532-d585-e71e545e7bf9"
      },
      "cell_type": "code",
      "source": [
        "GBR.score(X_finalval, y_finalval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7901517153918347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "metadata": {
        "id": "hid2fEjeLm1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "5f60340b-cb4d-4714-a6be-fe8df07da036"
      },
      "cell_type": "code",
      "source": [
        "y_finalval"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-269986052727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_finalval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_finalval' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fY_58iBcLm1g",
        "colab_type": "code",
        "colab": {},
        "outputId": "978bc095-f939-4e9b-96ae-54df9ee8e87c"
      },
      "cell_type": "code",
      "source": [
        "print(scipy.stats.kruskal(GBRnSV.predict(X_nSVtest), y_nSVtest))\n",
        "print(scipy.stats.kruskal(GBR.predict(X_finaltest),y_finaltest))\n",
        "print(scipy.stats.kruskal(GBR.predict(X_finaltest),GBRnSV.predict(X_nSVtest)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KruskalResult(statistic=94.59606977209059, pvalue=2.3348143801153684e-22)\n",
            "KruskalResult(statistic=98.20801470522338, pvalue=3.7666239843010957e-23)\n",
            "KruskalResult(statistic=0.031638759587793386, pvalue=0.8588228138954208)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-fGlMhrLm1j",
        "colab_type": "code",
        "colab": {},
        "outputId": "42ceb60b-3d37-4e89-ee39-aa5c85ff298c"
      },
      "cell_type": "code",
      "source": [
        "scipy.stats.kruskal((GBRnSV.predict(X_nSVtest), y_nSVtest),(y_finaltest,y_finaltest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KruskalResult(statistic=876810.1861107722, pvalue=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    }
  ]
}