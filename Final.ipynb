{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBC1fA8VNirF"
   },
   "source": [
    "# Real Estate Value Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zvc88TatNt6x"
   },
   "source": [
    "Our goal for this project is to determine if the exterior appearance of a building has predictive power in determining the real estate value of a home. \n",
    "\n",
    "We started with Boston property assessment data, which contains many features which can be used to indicate the value of a home. To get an accurate picture of real market value, we scraped sale prices from zillow for a subset of the properties. We scraped Google Street View images for these properties and extracted 25 features which describe qualities of the home and added those features as predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pg_SPzEJNCOP"
   },
   "source": [
    "#Boston Data\n",
    "\n",
    "Our Boston Data is acquired from data.boston.gov. The Boston Assessing Department, charged with  determining the value of property in Boston for the purposes of taxation, has helpfully released their information into the public domain. From their assessments of several different property types we focus on residential properties to acquire information regarding address, property value, building style, exterior and interior condition and several other indicators of value. A full list resides [here](https://data.boston.gov/dataset/property-assessment/resource/b8e32ddf-671f-4a35-b99f-c060bae958e5). We decided to focus on assessments in 2018, acquired [here](https://data.boston.gov/dataset/property-assessment/resource/fd351943-c2c6-4630-992d-3f895360febd), to apply our analysis on the most up to date information regarding Boston residential property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qZjUW8jOT0il"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boston = pd.read_csv(\"ast2018full.csv\", dtype = {15:str,60:str,63:str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIoKAHIsY5PM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>CM_ID</th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>ST_NUM</th>\n",
       "      <th>ST_NAME</th>\n",
       "      <th>ST_NAME_SUF</th>\n",
       "      <th>UNIT_NUM</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>PTYPE</th>\n",
       "      <th>LU</th>\n",
       "      <th>...</th>\n",
       "      <th>U_BTH_STYLE2</th>\n",
       "      <th>U_BTH_STYLE3</th>\n",
       "      <th>U_KITCH_TYPE</th>\n",
       "      <th>U_KITCH_STYLE</th>\n",
       "      <th>U_HEAT_TYP</th>\n",
       "      <th>U_AC</th>\n",
       "      <th>U_FPLACE</th>\n",
       "      <th>U_INT_FIN</th>\n",
       "      <th>U_INT_CND</th>\n",
       "      <th>U_VIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100001000.0</td>\n",
       "      <td>104 A 104</td>\n",
       "      <td>PUTNAM</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>105</td>\n",
       "      <td>R3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100002000.0</td>\n",
       "      <td>197</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>105</td>\n",
       "      <td>R3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100003000.0</td>\n",
       "      <td>199</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>105</td>\n",
       "      <td>R3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100004000.0</td>\n",
       "      <td>201</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>105</td>\n",
       "      <td>R3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100005000.0</td>\n",
       "      <td>203</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>104</td>\n",
       "      <td>R2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  CM_ID       GIS_ID     ST_NUM    ST_NAME ST_NAME_SUF UNIT_NUM  \\\n",
       "0  100001000    NaN  100001000.0  104 A 104     PUTNAM          ST      NaN   \n",
       "1  100002000    NaN  100002000.0        197  LEXINGTON          ST      NaN   \n",
       "2  100003000    NaN  100003000.0        199  LEXINGTON          ST      NaN   \n",
       "3  100004000    NaN  100004000.0        201  LEXINGTON          ST      NaN   \n",
       "4  100005000    NaN  100005000.0        203  LEXINGTON          ST      NaN   \n",
       "\n",
       "   ZIPCODE  PTYPE  LU   ...   U_BTH_STYLE2 U_BTH_STYLE3 U_KITCH_TYPE  \\\n",
       "0   2128.0    105  R3   ...            NaN          NaN          NaN   \n",
       "1   2128.0    105  R3   ...            NaN          NaN          NaN   \n",
       "2   2128.0    105  R3   ...            NaN          NaN          NaN   \n",
       "3   2128.0    105  R3   ...            NaN          NaN          NaN   \n",
       "4   2128.0    104  R2   ...            NaN          NaN          NaN   \n",
       "\n",
       "  U_KITCH_STYLE U_HEAT_TYP U_AC  U_FPLACE  U_INT_FIN  U_INT_CND  U_VIEW  \n",
       "0           NaN        NaN  NaN       NaN        NaN        NaN     NaN  \n",
       "1           NaN        NaN  NaN       NaN        NaN        NaN     NaN  \n",
       "2           NaN        NaN  NaN       NaN        NaN        NaN     NaN  \n",
       "3           NaN        NaN  NaN       NaN        NaN        NaN     NaN  \n",
       "4           NaN        NaN  NaN       NaN        NaN        NaN     NaN  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aVNNvbRZA07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/maria/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "boston.LU = boston.LU.astype(\"category\")\n",
    "boston.R_BLDG_STYL = boston.R_BLDG_STYL.astype(\"category\")\n",
    "\n",
    "residential_category = [\"A\",\"CD\",\"R1\",\"R2\",\"R3\",\"R4\",\"RL\"]\n",
    "residential_bool = [True if x in residential_category else False for x in boston.LU]\n",
    "residential = boston[residential_bool]\n",
    "\n",
    "residential.dropna(subset = [\"R_BLDG_STYL\"], inplace = True)\n",
    "\n",
    "residential.drop(labels = ['MAIL_ADDRESSEE', 'MAIL_ADDRESS', 'MAIL CS', \n",
    "                           'MAIL_ZIPCODE','PID', 'CM_ID', 'GIS_ID','OWNER',\n",
    "                           'S_BLDG_STYL', 'S_UNIT_RES', 'S_UNIT_COM',\n",
    "                           'S_UNIT_RC', 'S_EXT_FIN', 'S_EXT_CND'], \n",
    "                 axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "G6oE1a_SdXsC"
   },
   "outputs": [],
   "source": [
    "residential = residential.dropna(axis = 1, how = \"all\") #removing columns with only NA's\n",
    "residential = residential.dropna(axis = 0, how = \"all\") #removing rows with only NA's, there's none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N0MkfAWtddC2"
   },
   "outputs": [],
   "source": [
    "residential[\"ST_ADDRESS\"] = residential['ST_NUM'] + \" \" + residential['ST_NAME'] + \" \" + residential['ST_NAME_SUF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ExkAZJu1dfsP"
   },
   "outputs": [],
   "source": [
    "residential = residential.drop_duplicates(\"ST_ADDRESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_Ex6Zp6M6qG"
   },
   "source": [
    "# Scraping Zillow Data\n",
    "\n",
    "For scraping our Zillow response variables we used Chris Muir's Zillow's Scraper. He uses Python and Selenium to current home listings from given search terms. Acquired [here](https://github.com/ChrisMuir/Zillow) we go through the zillow_runfile.py and change the input search area to the Boston Zipcodes we want to scrape through.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXQNudO8iSFi"
   },
   "outputs": [],
   "source": [
    "zillow = pd.read_csv(\"Zillow/2018-05-07_210318.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRHi7gqvngUh"
   },
   "source": [
    "Before we can combine our data from Boston and Zillow we run through several cleaning measures regarding unrealistic Sold Prices, NA's in crucial predictor columns, inconsistent address formatting, and odd price inputs. After fixing these we combine the Boston and Zillow data sets on the addresses that appear in both and add in the Sold Prices and Addresses of those properties that we have full information for. We did these things half manually through Excel and some Python commands and as a result recreating the full data cleaning process is somewhat difficult. Our final CSV file containing  around 2000~ properties is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuaN48ndiSfn"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'residential_zillow.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-26291c760f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresidential_zillow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"residential_zillow.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/maria/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maria/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maria/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maria/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maria/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'residential_zillow.csv' does not exist"
     ]
    }
   ],
   "source": [
    "residential_zillow = pd.read_csv(\"residential_zillow.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSoHJTJ6Lm0t"
   },
   "source": [
    "# Scraping Street View Data\n",
    "Using the Google Street View API we acquire images from all the properties in our combined data. Scraping the images for our properties took around 3 minutes but we then had to manually parse through all images and remove those that were invalid where invalid is defined as the property being occluded by trees, trucks, or otherwise bad image captures due to angle and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qzbD2e7oLm0u"
   },
   "outputs": [],
   "source": [
    "import urllib, os\n",
    "count = 0\n",
    "myloc = r\"streetView\" #replace with your own location\n",
    "key = \"&key=AIzaSyBYG7d1Nml_Z6emFfRdqSnJj6065HBFekY\"\n",
    "def GetStreet(Add,SaveLoc, count):\n",
    "    base = \"https://maps.googleapis.com/maps/api/streetview?size=640x480&fov=90&location=\"\n",
    "    MyUrl = base + urllib.parse.quote_plus(Add) + key  #added url encoding\n",
    "    fi = str(count) + \".jpg\"\n",
    "    urllib.request.urlretrieve(MyUrl, os.path.join(SaveLoc,fi))\n",
    "    count += 1\n",
    "\n",
    "for location in names:\n",
    "    GetStreet(Add=location,SaveLoc=myloc, count=count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ng315NFdqvkQ"
   },
   "outputs": [],
   "source": [
    "#Example Output\n",
    "im = Image.open(\"streetView/0.jpg\")\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zDiaMJ-8Lm0w"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('streetViewX.pickle', 'rb') as handle:\n",
    "    X_SV = pickle.load(handle)\n",
    "with open('streetViewy.pickle', 'rb') as handle:\n",
    "    y_SV = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2oGB4w7s0gz"
   },
   "source": [
    "# Architectural Style Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCHfeP4ks4_J"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbUOoSIZSiQm"
   },
   "source": [
    "# Processing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HiibgUPdSuNJ"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "import keras.preprocessing.image as KerasImage\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROdh_6kPjGOo"
   },
   "source": [
    "We used the VGG19 model to process images.  The model can be downloaded through Keras with the weights pretrained on the imagenet dataset. You can read more about the model [here](https://arxiv.org/pdf/1409.1556.pdf). \n",
    "\n",
    "The model was originally trained to classify objects like cats and dogs, which isn't the task on hand. However, we can still use the model to process our images and output useful vectors.\n",
    "\n",
    "We can modify the model relatively easily with Keras, which allows us to strip the classifying layers from the model and use a custom input image vector to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "seYbwDxVSydG"
   },
   "outputs": [],
   "source": [
    "model = VGG19(include_top=False, input_shape=(800,600,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C90A7WXqlXbg"
   },
   "source": [
    "The default model outputs a four dimensional array, so we'll have to flatten that into a 1d vector in order to properly interface with the outputs later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rLQABNHjV9UG"
   },
   "outputs": [],
   "source": [
    "output = model.get_layer('block5_pool').output\n",
    "output = keras.layers.Flatten()(output)\n",
    "model = keras.models.Model(model.input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTQIVK1vng5M"
   },
   "source": [
    "Our architectural style dataset was organized such that each unique style classification had its own folder containing the images which belonged to that class. \n",
    "\n",
    "The following code traverses the parent folder, pushes each image through the VGG model, and labels the resulting vectors with the appropriate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mHBK0mMCWcKm"
   },
   "outputs": [],
   "source": [
    "# Open the specified folder and get all the subdirectories\n",
    "dname = \"D:\\\\DataScience\\\\arcDataset\"\n",
    "sdnames = os.listdir(dname)\n",
    "\n",
    "# Set up dummy arrays to hold the processed features and labels \n",
    "y = np.array([-1])\n",
    "X = np.array([i for i in range(230400)])\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(sdnames):\n",
    "    sdname = sdnames[i] + '/'\n",
    "               \n",
    "    # Ignore non-directory files \n",
    "    try: fnames = os.listdir(dname + sdname)\n",
    "    except: continue\n",
    "               \n",
    "    for j in range(len(fnames)):\n",
    "        fname = dname + sdname + fnames[j]\n",
    "        \n",
    "        # Ignore non-image files\n",
    "        try: im = KerasImage.load_img(fname, target_size=(800,600))\n",
    "        except: continue\n",
    "               \n",
    "        # Print out a message to show progression \n",
    "        count += 1\n",
    "        sys.stdout.write(\"\\rsdir: \" + str(i) + \" im: \" + str(j))\n",
    "        sys.stdout.flush()\n",
    "               \n",
    "        # Format image properly\n",
    "        im = KerasImage.img_to_array(im)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        \n",
    "        # Push image through the model\n",
    "        im = preprocess_input(im)\n",
    "        im = model.predict(im)\n",
    "        \n",
    "        # Correct shape of output vector\n",
    "        im = np.squeeze(im)\n",
    "        \n",
    "        # Add vector to X and label to y\n",
    "        X = np.append(X, im, axis=0)\n",
    "        y = np.append(y, np.array([i]), axis=0)\n",
    "\n",
    "# Delete the placeholder vectors\n",
    "X = np.delete(X, range(230400), axis=0)\n",
    "y = np.delete(y, 0, axis=0)\n",
    "\n",
    "# Reshape the features               \n",
    "X = X.reshape(count, 230400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ma2OTEvvqUXz"
   },
   "source": [
    "We went through a similar process for our street view images. The code is nearly identical, just with a few lines commented out because the data was unlabeled and because we did not need to traverse a file structure in the same way.\n",
    "\n",
    "We've omitted this code for the sake of brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZLozmnssCC9"
   },
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-4jlV0ksikx"
   },
   "source": [
    "To turn these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Mfijp6UGLm0d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZScKE36NLm0g"
   },
   "outputs": [],
   "source": [
    "with open('arcDataX.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "with open('arcDatay.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xKO2xCaVLm0j"
   },
   "outputs": [],
   "source": [
    "X_arctr, X_arctest, y_arctr, y_arctest = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "X_arctest, X_arcval, y_arctest, y_arcval = train_test_split(X_arctest, y_arctest, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_4Bv6I-Lm0m",
    "outputId": "d9ac05d3-d726-43b8-8b90-60cdbab89413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=3000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arc = LR(random_state = 0, dual=False, max_iter=3000)\n",
    "model_arc.fit(X_arctr, y_arctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDG0unXlLm0p",
    "outputId": "36baf248-2000-4b3f-fac7-3050390bf509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702928870292887"
      ]
     },
     "execution_count": 216,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arc.score(X_arctest, y_arctest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnK6LZ30MAXV"
   },
   "source": [
    "# Adding Features to Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7r1Z1RlkLm0y"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"residential_zillow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ix6fvrV0Lm01"
   },
   "outputs": [],
   "source": [
    "#indexed with valid images\n",
    "df_final = data.iloc()[y_SV.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Fg3I8wAOLm04"
   },
   "outputs": [],
   "source": [
    "X_SVC = model_arc.predict_proba(X_SV)\n",
    "\n",
    "X_SVCdf = pd.DataFrame(data=X_SVC, index=y_SV);\n",
    "\n",
    "X_SVCdf.index = X_SVCdf.index.astype(int)\n",
    "\n",
    "df_final1 = pd.concat([df_final, X_SVCdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "X6aIozmiLm07"
   },
   "outputs": [],
   "source": [
    "y_final = df_final1['SALE_PRICE']\n",
    "\n",
    "X_final = df_final1.drop('SALE_PRICE', axis=1)\n",
    "X_final = X_final.drop(['ST_NUM', 'ST_NAME', 'ST_NAME_SUF', 'AV_LAND', 'AV_BLDG', 'AV_TOTAL', 'GROSS_TAX', 'ST_ADDRESS','PTYPE'], axis=1)\n",
    "\n",
    "X_final = pd.get_dummies(X_final, columns=['R_BLDG_STYL','LU','OWN_OCC','STRUCTURE_CLASS','R_ROOF_TYP','R_EXT_FIN','R_EXT_CND','R_BTH_STYLE','R_BTH_STYLE2','R_BTH_STYLE3','R_KITCH_STYLE','R_KITCH_STYLE2','R_KITCH_STYLE3','R_HEAT_TYP','R_AC','R_OVRALL_CND','R_INT_CND','R_INT_FIN','R_VIEW'])\n",
    "X_final = X_final.astype(np.float32).fillna(0)\n",
    "\n",
    "# X_final = X_final.reset_index().drop('index', axis=1)\n",
    "# y_final = y_final.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6yhtEZz7Lm0_"
   },
   "outputs": [],
   "source": [
    "X_final = X_final.drop('Unnamed: 0', axis=1).reset_index(drop=True)\n",
    "y_final = y_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFxbSiRhLm1A",
    "outputId": "0a328f64-77fb-4f35-8377-2624e5cd0a41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIPCODE             0.079714\n",
       "LAND_SF             0.263169\n",
       "YR_BUILT            0.053118\n",
       "YR_REMOD            0.060519\n",
       "GROSS_AREA          0.301567\n",
       "LIVING_AREA         0.303270\n",
       "NUM_FLOORS          0.072153\n",
       "R_TOTAL_RMS        -0.009428\n",
       "R_BDRMS            -0.014479\n",
       "R_FULL_BTH          0.013468\n",
       "R_HALF_BTH          0.005019\n",
       "R_KITCH            -0.055054\n",
       "R_FPLACE            0.078625\n",
       "0                   0.371457\n",
       "1                   0.371457\n",
       "2                   0.371457\n",
       "3                   0.371457\n",
       "4                   0.371457\n",
       "5                   0.371457\n",
       "6                   0.371457\n",
       "7                   0.371457\n",
       "8                   0.371457\n",
       "9                   0.371457\n",
       "10                  0.371457\n",
       "11                  0.371457\n",
       "12                  0.371457\n",
       "13                  0.371457\n",
       "14                  0.371457\n",
       "15                  0.371457\n",
       "16                  0.371457\n",
       "                      ...   \n",
       "R_KITCH_STYLE3_N   -0.034522\n",
       "R_KITCH_STYLE3_S   -0.056608\n",
       "R_HEAT_TYP_E       -0.022175\n",
       "R_HEAT_TYP_F        0.013484\n",
       "R_HEAT_TYP_N       -0.019901\n",
       "R_HEAT_TYP_O       -0.024673\n",
       "R_HEAT_TYP_P       -0.002974\n",
       "R_HEAT_TYP_S       -0.035530\n",
       "R_HEAT_TYP_W       -0.004737\n",
       "R_AC_C              0.078809\n",
       "R_AC_D             -0.028873\n",
       "R_AC_N              0.072534\n",
       "R_OVRALL_CND_A      0.047183\n",
       "R_OVRALL_CND_E      0.070352\n",
       "R_OVRALL_CND_F      0.002341\n",
       "R_OVRALL_CND_G      0.027799\n",
       "R_OVRALL_CND_P     -0.009365\n",
       "R_INT_CND_A        -0.041118\n",
       "R_INT_CND_E         0.082973\n",
       "R_INT_CND_F         0.023095\n",
       "R_INT_CND_G        -0.009477\n",
       "R_INT_CND_P        -0.009365\n",
       "R_INT_FIN_E         0.100286\n",
       "R_INT_FIN_N         0.100286\n",
       "R_VIEW_A            0.001133\n",
       "R_VIEW_E            0.012223\n",
       "R_VIEW_F           -0.004389\n",
       "R_VIEW_G            0.014428\n",
       "R_VIEW_P           -0.034147\n",
       "Value               1.000000\n",
       "Name: Value, Length: 133, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.assign(Value =y_final.squeeze()).apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0-Z_AIO1Lm1F"
   },
   "outputs": [],
   "source": [
    "X_finaltr, X_finaltest, y_finaltr, y_finaltest = train_test_split(X_final, y_final, test_size=0.3, random_state=5)\n",
    "X_finaltest, X_finalval, y_finaltest, y_finalval = train_test_split(X_finaltest, y_finaltest, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LaYS6tEMdrd"
   },
   "source": [
    "## Cross-Validating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mW-Pi4-ELm1H",
    "outputId": "90bbbfb3-9638-446c-dc88-636dd24cd2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 2 - score: 0.563488374663454\n",
      "testing 2 - score: 0.5497977215495489\n",
      "testing 2 - score: 0.564611005381296\n",
      "avg for 2: 0.5592990338647663\n",
      "testing 3 - score: 0.550701541561935\n",
      "testing 3 - score: 0.5742114205959534\n",
      "testing 3 - score: 0.5532390351072125\n",
      "avg for 3: 0.559383999088367\n",
      "testing 1 - score: 0.5656458563598071\n",
      "testing 1 - score: 0.5625804955060273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-14230b3e6392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumTrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mGBR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quantile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finaltr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finaltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcurScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finalval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finalval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcurScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n\u001b[1;32m    797\u001b[0m                                              \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                              self.learning_rate, k=k)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m# add tree to ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, y_pred, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    247\u001b[0m             self._update_terminal_region(tree, masked_terminal_regions,\n\u001b[1;32m    248\u001b[0m                                          \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                          y_pred[:, k], sample_weight)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# update predictions (both in-bag and out-of-bag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_update_terminal_region\u001b[0;34m(self, tree, terminal_regions, leaf, X, y, residual, pred, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m                                 residual, pred, sample_weight):\n\u001b[1;32m    436\u001b[0m         \u001b[0mterminal_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_regions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         diff = (y.take(terminal_region, axis=0)\n\u001b[0m\u001b[1;32m    438\u001b[0m                 - pred.take(terminal_region, axis=0))\n\u001b[1;32m    439\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "to_try = [2,3,1]\n",
    "numTrials = 3\n",
    "best = 0\n",
    "bestVal = 0\n",
    "for val in to_try: \n",
    "    score = 0\n",
    "    for i in range(numTrials):\n",
    "        GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
    "                                    subsample=.99,alpha=.89)\n",
    "        GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
    "        curScore = GBR.score(X_finalval, y_finalval.squeeze())\n",
    "        score += curScore\n",
    "        print(\"testing \" + str(val) + \" - score: \" + str(curScore))\n",
    "    score /= 3\n",
    "    print(\"avg for \" + str(val) + \": \" + str(score))\n",
    "    if score > best: \n",
    "        best = score\n",
    "        bestVal = val\n",
    "print(\"best choice is: \" + str(bestVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgzUggUGLm1K",
    "outputId": "8305d6b1-1d30-46bd-90eb-81b14f24d953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7901517153918347"
      ]
     },
     "execution_count": 222,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
    "                            subsample=.99,alpha=.89)\n",
    "GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
    "GBR.score(X_finalval, y_finalval.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EyxpCYbGLm1Q"
   },
   "outputs": [],
   "source": [
    "X_nSV = X_final.drop(labels=list(range(25)), axis=1)\n",
    "y_nSV = y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ft9nHkjKLm1S"
   },
   "outputs": [],
   "source": [
    "X_nSVtr, X_nSVtest, y_nSVtr, y_nSVtest = train_test_split(X_nSV, y_nSV, test_size=0.3, random_state=5)\n",
    "X_nSVtest, X_nSVval, y_nSVtest, y_nSVval = train_test_split(X_nSVtest, y_nSVtest, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7XJ4aMxLm1W",
    "outputId": "63a267c9-8b56-42b1-e337-e5887d602a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36443930091932547"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBRnSV = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
    "                                    subsample=.99,alpha=.89)\n",
    "GBRnSV.fit(X_nSVtr, y_nSVtr)\n",
    "\n",
    "GBRnSV.score(X_nSVval, y_nSVval.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2RH2EauLm1Z",
    "outputId": "4a9098d5-bc9d-4532-d585-e71e545e7bf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7901517153918347"
      ]
     },
     "execution_count": 232,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBR.score(X_finalval, y_finalval.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "colab_type": "code",
    "id": "hid2fEjeLm1c",
    "outputId": "5f60340b-cb4d-4714-a6be-fe8df07da036"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-269986052727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_finalval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_finalval' is not defined"
     ]
    }
   ],
   "source": [
    "y_finalval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fY_58iBcLm1g",
    "outputId": "978bc095-f939-4e9b-96ae-54df9ee8e87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=94.59606977209059, pvalue=2.3348143801153684e-22)\n",
      "KruskalResult(statistic=98.20801470522338, pvalue=3.7666239843010957e-23)\n",
      "KruskalResult(statistic=0.031638759587793386, pvalue=0.8588228138954208)\n"
     ]
    }
   ],
   "source": [
    "print(scipy.stats.kruskal(GBRnSV.predict(X_nSVtest), y_nSVtest))\n",
    "print(scipy.stats.kruskal(GBR.predict(X_finaltest),y_finaltest))\n",
    "print(scipy.stats.kruskal(GBR.predict(X_finaltest),GBRnSV.predict(X_nSVtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-fGlMhrLm1j",
    "outputId": "42ceb60b-3d37-4e89-ee39-aa5c85ff298c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=876810.1861107722, pvalue=0.0)"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal((GBRnSV.predict(X_nSVtest), y_nSVtest),(y_finaltest,y_finaltest))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
