{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mad100141/final15388/blob/master/Final.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YBC1fA8VNirF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Real Estate Value Estimation"
      ]
    },
    {
      "metadata": {
        "id": "Zvc88TatNt6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our goal for this project is to determine if the exterior appearance of a building has predictive power in determining the real estate value of a home. \n",
        "\n",
        "We started with Boston property assessment data, which contains many features which can be used to indicate the value of a home. To get an accurate picture of real market value, we scraped sale prices from zillow for a subset of the properties. We scraped Google Street View images for these properties and extracted 25 features which describe qualities of the home and added those features as predictor variables."
      ]
    },
    {
      "metadata": {
        "id": "Pg_SPzEJNCOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Boston Data\n",
        "\n",
        "We took a property assessment dataset from data.boston.gov [[source](https://data.boston.gov/dataset/property-assessment/resource/fd351943-c2c6-4630-992d-3f895360febd)]. This dataset contains information which the Boston municipality uses to gague value and set property taxes for buildings.\n",
        "\n",
        "We kept only the data for residential buildings to avoid inconsistencies across real estate markets, and removed many features which we deemed unnecessary for our purposes. We removed the city's appraised value because these values do not actually track market prices and can be skewed for any number of reasons. We also removed the given building style because we wanted to minimize the redunancy of information provided by the street view images.\n",
        "\n",
        "This dataset has features which primarily pertain to the building itself. Other than the zipcode, the data contains minimal information about the building's context, which determines much of the building's market value. The lack of information about location makes the value estimation task difficult, but we thought that street view images would give some information about context and would help to fill this gap."
      ]
    },
    {
      "metadata": {
        "id": "qZjUW8jOT0il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "boston = pd.read_csv(\"ast2018full.csv\", dtype = {15:str,60:str,63:str})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIoKAHIsY5PM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1aVNNvbRZA07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston.LU = boston.LU.astype(\"category\")\n",
        "\n",
        "# Remove all data for non-residential buildings\n",
        "residential_category = [\"A\",\"CD\",\"R1\",\"R2\",\"R3\",\"R4\",\"RL\"]\n",
        "residential_bool = [True if x in residential_category else False for x in boston.LU]\n",
        "residential = boston[residential_bool]\n",
        "\n",
        "residential = residential.drop(labels = ['MAIL_ADDRESSEE', 'MAIL_ADDRESS', 'MAIL CS', \n",
        "                           'MAIL_ZIPCODE','PID', 'CM_ID', 'GIS_ID','OWNER',\n",
        "                           'S_BLDG_STYL', 'S_UNIT_RES', 'S_UNIT_COM',\n",
        "                           'S_UNIT_RC', 'S_EXT_FIN', 'S_EXT_CND'], \n",
        "                 axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6oE1a_SdXsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#removing rows and columns with only NA's\n",
        "residential = residential.dropna(axis = 1, how = \"all\") \n",
        "residential = residential.dropna(axis = 0, how = \"all\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9vLL4wDS0j9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After cleaning the data a bit, we need to create a way to easily access the street address so we can pull in other sources of data."
      ]
    },
    {
      "metadata": {
        "id": "N0MkfAWtddC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential[\"ST_ADDRESS\"] = residential['ST_NUM'] + \" \" + residential['ST_NAME'] + \" \" + residential['ST_NAME_SUF']\n",
        "\n",
        "residential = residential.drop_duplicates(\"ST_ADDRESS\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_Ex6Zp6M6qG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scraping Zillow Data\n",
        "\n",
        "For scraping our Zillow response variables we used Chris Muir's Zillow's Scraper, which uses Python and Selenium to scrape Zillow postings [[source](https://github.com/ChrisMuir/Zillow)]. This code is contained in several files and opens new instances of Google Chrome, which cannot be done from a Jupyter notebook. Instead, we ran it locally and saved out csv files. We also cleaned the data in excel, which proved to be much faster and easier than doing it from Jupyter.\n",
        "\n",
        "We used the scraper to scrape sale prices for recently sold homes only, which kept issues of inflation from entering our data. We manually cleaned this data in excel, removing unrealistic sales prices, entries with missing data, and inconsistent address formats.\n",
        "\n",
        "The final csv holds around 2000 entries."
      ]
    },
    {
      "metadata": {
        "id": "PuaN48ndiSfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "residential_zillow = pd.read_csv(\"residential_zillow.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSoHJTJ6Lm0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scraping Street View Data\n",
        "Using the Google Street View API, we acquired images from all the properties in our combined dataset. Scraping the images for the 2000 properties took around 3 minutes, but we then had to manually parse through all images and remove images where an invalid image was returned, the image did not contain a picture of the building, or the building was occluded by trees or trucks."
      ]
    },
    {
      "metadata": {
        "id": "qzbD2e7oLm0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib, os\n",
        "count = 0\n",
        "saveDir = r\"streetView\"\n",
        "key = \"\" #redacted\n",
        "\n",
        "def GetSV (location):\n",
        "    base = \"https://maps.googleapis.com/maps/api/streetview?size=640x480&fov=90&location=\"\n",
        "    request = base + urllib.parse.quote_plus(location) + key\n",
        "    \n",
        "    # Name the image with the index \n",
        "    index = str(count) + \".jpg\"\n",
        "    urllib.request.urlretrieve(request, os.path.join(saveDir, index))\n",
        "\n",
        "for location in list(residential_subset.ST_ADDRESS):\n",
        "    GetSV (location)\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ng315NFdqvkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Example Output\n",
        "import matplotlib.pyplot as plt\n",
        "im = Image.open(\"streetView/0.jpg\")\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2oGB4w7s0gz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Architectural Style Dataset"
      ]
    },
    {
      "metadata": {
        "id": "fCHfeP4ks4_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to extract useful information about a building from an image, we need to train a machine leaning model to pick up on aspects buildings. One way to do this is to classify architectural style. \n",
        "\n",
        "For this, we found a labeled dataset [[source](https://drive.google.com/file/d/0Bwo0SFiZwl3JVGRlWGZUaW5va00/edit)] of 25 architectural styles. These architectural styles do not necessarily line up with the architectural styles from the street view images, but will capture common defining features, so we will simply use the probabilities of each style as an indicator for _some_ style. While this doesn't quite capture style, it does add some information about the underlying features of the 25 styles. \n",
        "\n",
        "We found that these raw probabilities had a higher correlation with the market value than the style classification itself."
      ]
    },
    {
      "metadata": {
        "id": "gbUOoSIZSiQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Processing Images"
      ]
    },
    {
      "metadata": {
        "id": "HiibgUPdSuNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "import keras.preprocessing.image as KerasImage\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROdh_6kPjGOo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We used the VGG19 model to process images.  The model can be downloaded through Keras with the weights pretrained on the imagenet dataset. You can read more about the model [here](https://arxiv.org/pdf/1409.1556.pdf). \n",
        "\n",
        "The model was originally trained to classify objects like cats and dogs, which isn't the task on hand. However, we can still use the model to process our images and output useful vectors.\n",
        "\n",
        "We can modify the model relatively easily with Keras, which allows us to strip the classifying layers from the model and use a custom input image vector to "
      ]
    },
    {
      "metadata": {
        "id": "seYbwDxVSydG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = VGG19(include_top=False, input_shape=(800,600,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C90A7WXqlXbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The default model outputs a four dimensional array, so we'll have to flatten that into a 1d vector in order to properly interface with the outputs later on"
      ]
    },
    {
      "metadata": {
        "id": "rLQABNHjV9UG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = model.get_layer('block5_pool').output\n",
        "output = keras.layers.Flatten()(output)\n",
        "model = keras.models.Model(model.input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FTQIVK1vng5M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our architectural style dataset was organized such that each unique style classification had its own folder containing the images which belonged to that class. \n",
        "\n",
        "The following code traverses the parent folder, pushes each image through the VGG model, and labels the resulting vectors with the appropriate class."
      ]
    },
    {
      "metadata": {
        "id": "mHBK0mMCWcKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open the specified folder and get all the subdirectories\n",
        "dname = \"D:\\\\DataScience\\\\arcDataset\"\n",
        "sdnames = os.listdir(dname)\n",
        "\n",
        "# Set up dummy arrays to hold the processed features and labels \n",
        "y = np.array([-1])\n",
        "X = np.array([i for i in range(230400)])\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in range(len(sdnames):\n",
        "    sdname = sdnames[i] + '/'\n",
        "               \n",
        "    # Ignore non-directory files \n",
        "    try: fnames = os.listdir(dname + sdname)\n",
        "    except: continue\n",
        "               \n",
        "    for j in range(len(fnames)):\n",
        "        fname = dname + sdname + fnames[j]\n",
        "        \n",
        "        # Ignore non-image files\n",
        "        try: im = KerasImage.load_img(fname, target_size=(800,600))\n",
        "        except: continue\n",
        "               \n",
        "        # Print out a message to show progression \n",
        "        count += 1\n",
        "        sys.stdout.write(\"\\rsdir: \" + str(i) + \" im: \" + str(j))\n",
        "        sys.stdout.flush()\n",
        "               \n",
        "        # Format image properly\n",
        "        im = KerasImage.img_to_array(im)\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        \n",
        "        # Push image through the model\n",
        "        im = preprocess_input(im)\n",
        "        im = model.predict(im)\n",
        "        \n",
        "        # Correct shape of output vector\n",
        "        im = np.squeeze(im)\n",
        "        \n",
        "        # Add vector to X and label to y\n",
        "        X = np.append(X, im, axis=0)\n",
        "        y = np.append(y, np.array([i]), axis=0)\n",
        "\n",
        "# Delete the placeholder vectors\n",
        "X = np.delete(X, range(230400), axis=0)\n",
        "y = np.delete(y, 0, axis=0)\n",
        "\n",
        "# Reshape the features               \n",
        "X = X.reshape(count, 230400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ma2OTEvvqUXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We went through a similar process for our street view images. The code is nearly identical, just with a few lines commented out because the data was unlabeled and because we did not need to traverse a file structure in the same way. We've omitted this code for the sake of brevity.\n",
        "\n",
        "\n",
        "To avoid unneccessarily running this compute-heavy code, we saved out the results as pickle files, which we loaded as necessary."
      ]
    },
    {
      "metadata": {
        "id": "tZLozmnssCC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression for Style Classification"
      ]
    },
    {
      "metadata": {
        "id": "S-4jlV0ksikx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We took the 230,400 feature vectors output from VGG19 and trained a logistic regression model on the architectural style dataset to classify style. We then used the trained model to output the raw class probabilities of the street view images."
      ]
    },
    {
      "metadata": {
        "id": "Mfijp6UGLm0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import scipy.stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2aqmItCoP_Jz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('arcDataX.pickle', 'rb') as file:\n",
        "    X = pickle.load(file)\n",
        "with open('arcDatay.pickle', 'rb') as file:\n",
        "    y = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKO2xCaVLm0j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split the data into train, validate, and test sets\n",
        "X_arctr, X_arctest, y_arctr, y_arctest = train_test_split(X, y, test_size=0.3, random_state=5)\n",
        "X_arctest, X_arcval, y_arctest, y_arcval = train_test_split(X_arctest, y_arctest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zu7AtML38fcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The logistic regression gave a reasonably good fit without modifying much. In the end, since we aren't _really_ classifying architectural style, this seemed reasonable enough to leave as is."
      ]
    },
    {
      "metadata": {
        "id": "m_4Bv6I-Lm0m",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9ac05d3-d726-43b8-8b90-60cdbab89413"
      },
      "cell_type": "code",
      "source": [
        "model_arc = LR(random_state = 0, dual=False, max_iter=3000)\n",
        "model_arc.fit(X_arctr, y_arctr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=3000, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "metadata": {
        "id": "HDG0unXlLm0p",
        "colab_type": "code",
        "colab": {},
        "outputId": "36baf248-2000-4b3f-fac7-3050390bf509"
      },
      "cell_type": "code",
      "source": [
        "model_arc.score(X_arcval, y_arcval)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.702928870292887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "metadata": {
        "id": "pnK6LZ30MAXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Adding Features to Original Dataset"
      ]
    },
    {
      "metadata": {
        "id": "DOXvxNHYQlUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have our logistic regression model trained, we need to combine all of our features."
      ]
    },
    {
      "metadata": {
        "id": "zDiaMJ-8Lm0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load VGG19 outputs for street view images\n",
        "import pickle\n",
        "with open('streetViewX.pickle', 'rb') as file:\n",
        "    X_SV = pickle.load(file)\n",
        "with open('streetViewy.pickle', 'rb') as file:\n",
        "    y_SV = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V65X-kUYSEQV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After sifting through the street view images, we came across a number that were not useful for our purposes. Since this happened outside of the scope of our Jupyter notebook, we need to make sure we are only operating on entries with valid street view data."
      ]
    },
    {
      "metadata": {
        "id": "ix6fvrV0Lm01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Indexed with valid images\n",
        "df_final = residential_zillow.iloc()[y_SV.astype(int)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMYv6MkDSjzE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to get the 25 style classification probabilities and insert them as features in our dataset."
      ]
    },
    {
      "metadata": {
        "id": "Fg3I8wAOLm04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run the logistic regression model on the street view images\n",
        "X_SVC = model_arc.predict_proba(X_SV)\n",
        "\n",
        "X_SVCdf = pd.DataFrame(data=X_SVC, index=y_SV);\n",
        "X_SVCdf.index = X_SVCdf.index.astype(int)\n",
        "df_final = pd.concat([df_final, X_SVCdf], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGj1UztVVOju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And now some final data cleaning.."
      ]
    },
    {
      "metadata": {
        "id": "X6aIozmiLm07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_final = df_final['SALE_PRICE']\n",
        "\n",
        "X_final = df_final.drop('SALE_PRICE', axis=1)\n",
        "X_final = X_final.drop(['ST_NUM', 'ST_NAME', 'ST_NAME_SUF', 'AV_LAND', 'AV_BLDG', 'AV_TOTAL', 'GROSS_TAX', 'ST_ADDRESS','PTYPE'], axis=1)\n",
        "\n",
        "X_final = pd.get_dummies(X_final, columns=['R_BLDG_STYL','LU','OWN_OCC','STRUCTURE_CLASS','R_ROOF_TYP','R_EXT_FIN','R_EXT_CND','R_BTH_STYLE',\\\n",
        "                                           'R_BTH_STYLE2','R_BTH_STYLE3','R_KITCH_STYLE','R_KITCH_STYLE2','R_KITCH_STYLE3','R_HEAT_TYP','R_AC',\\\n",
        "                                           'R_OVRALL_CND','R_INT_CND','R_INT_FIN','R_VIEW'])\n",
        "\n",
        "X_final = X_final.astype(np.float32).fillna(0)\n",
        "\n",
        "X_final = X_final.drop('Unnamed: 0', axis=1).reset_index(drop=True)\n",
        "y_final = y_final.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFxbSiRhLm1A",
        "colab_type": "code",
        "colab": {},
        "outputId": "0a328f64-77fb-4f35-8377-2624e5cd0a41"
      },
      "cell_type": "code",
      "source": [
        "X_final.assign(Value =y_final.squeeze()).apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)['Value']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ZIPCODE             0.079714\n",
              "LAND_SF             0.263169\n",
              "YR_BUILT            0.053118\n",
              "YR_REMOD            0.060519\n",
              "GROSS_AREA          0.301567\n",
              "LIVING_AREA         0.303270\n",
              "NUM_FLOORS          0.072153\n",
              "R_TOTAL_RMS        -0.009428\n",
              "R_BDRMS            -0.014479\n",
              "R_FULL_BTH          0.013468\n",
              "R_HALF_BTH          0.005019\n",
              "R_KITCH            -0.055054\n",
              "R_FPLACE            0.078625\n",
              "0                   0.371457\n",
              "1                   0.371457\n",
              "2                   0.371457\n",
              "3                   0.371457\n",
              "4                   0.371457\n",
              "5                   0.371457\n",
              "6                   0.371457\n",
              "7                   0.371457\n",
              "8                   0.371457\n",
              "9                   0.371457\n",
              "10                  0.371457\n",
              "11                  0.371457\n",
              "12                  0.371457\n",
              "13                  0.371457\n",
              "14                  0.371457\n",
              "15                  0.371457\n",
              "16                  0.371457\n",
              "                      ...   \n",
              "R_KITCH_STYLE3_N   -0.034522\n",
              "R_KITCH_STYLE3_S   -0.056608\n",
              "R_HEAT_TYP_E       -0.022175\n",
              "R_HEAT_TYP_F        0.013484\n",
              "R_HEAT_TYP_N       -0.019901\n",
              "R_HEAT_TYP_O       -0.024673\n",
              "R_HEAT_TYP_P       -0.002974\n",
              "R_HEAT_TYP_S       -0.035530\n",
              "R_HEAT_TYP_W       -0.004737\n",
              "R_AC_C              0.078809\n",
              "R_AC_D             -0.028873\n",
              "R_AC_N              0.072534\n",
              "R_OVRALL_CND_A      0.047183\n",
              "R_OVRALL_CND_E      0.070352\n",
              "R_OVRALL_CND_F      0.002341\n",
              "R_OVRALL_CND_G      0.027799\n",
              "R_OVRALL_CND_P     -0.009365\n",
              "R_INT_CND_A        -0.041118\n",
              "R_INT_CND_E         0.082973\n",
              "R_INT_CND_F         0.023095\n",
              "R_INT_CND_G        -0.009477\n",
              "R_INT_CND_P        -0.009365\n",
              "R_INT_FIN_E         0.100286\n",
              "R_INT_FIN_N         0.100286\n",
              "R_VIEW_A            0.001133\n",
              "R_VIEW_E            0.012223\n",
              "R_VIEW_F           -0.004389\n",
              "R_VIEW_G            0.014428\n",
              "R_VIEW_P           -0.034147\n",
              "Value               1.000000\n",
              "Name: Value, Length: 133, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "0-Z_AIO1Lm1F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_finaltr, X_finaltest, y_finaltr, y_finaltest = train_test_split(X_final, y_final, test_size=0.3, random_state=5)\n",
        "X_finaltest, X_finalval, y_finaltest, y_finalval = train_test_split(X_finaltest, y_finaltest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EyxpCYbGLm1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_nSV = X_final.drop(labels=list(range(25)), axis=1)\n",
        "y_nSV = y_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ft9nHkjKLm1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_nSVtr, X_nSVtest, y_nSVtr, y_nSVtest = train_test_split(X_nSV, y_nSV, test_size=0.3, random_state=5)\n",
        "X_nSVtest, X_nSVval, y_nSVtest, y_nSVval = train_test_split(X_nSVtest, y_nSVtest, test_size=0.5, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LaYS6tEMdrd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-Validating Hyperparameters\n",
        "\n",
        "We applied cross validation on our Gradient Boosting Regressor model to acquire the best parameters. Below we show an example but when we were finding the best parameters we ran 5 trials for each value we wanted to try. We applied cross validation on n_estimators, loss, learning_rate, max_depth, subsample, and alpha. For each parameter we took the value that resulted with the best score and added it to our model as we continue testing through the rest of our parameters."
      ]
    },
    {
      "metadata": {
        "id": "DMMWGobtThTV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mW-Pi4-ELm1H",
        "colab_type": "code",
        "colab": {},
        "collapsed": true,
        "outputId": "90bbbfb3-9638-446c-dc88-636dd24cd2ae"
      },
      "cell_type": "code",
      "source": [
        "to_try = [2,3,1]\n",
        "numTrials = 5\n",
        "best = 0\n",
        "bestVal = 0\n",
        "for val in to_try: \n",
        "    score = 0\n",
        "    for i in range(numTrials):\n",
        "        GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                                    subsample=.99,alpha=.89)\n",
        "        GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
        "        curScore = GBR.score(X_finalval, y_finalval.squeeze())\n",
        "        score += curScore\n",
        "        print(\"testing \" + str(val) + \" - score: \" + str(curScore))\n",
        "    score /= 3\n",
        "    print(\"avg for \" + str(val) + \": \" + str(score))\n",
        "    if score > best: \n",
        "        best = score\n",
        "        bestVal = val\n",
        "print(\"best choice is: \" + str(bestVal))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing 2 - score: 0.563488374663454\n",
            "testing 2 - score: 0.5497977215495489\n",
            "testing 2 - score: 0.564611005381296\n",
            "avg for 2: 0.5592990338647663\n",
            "testing 3 - score: 0.550701541561935\n",
            "testing 3 - score: 0.5742114205959534\n",
            "testing 3 - score: 0.5532390351072125\n",
            "avg for 3: 0.559383999088367\n",
            "testing 1 - score: 0.5656458563598071\n",
            "testing 1 - score: 0.5625804955060273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-215-14230b3e6392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumTrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mGBR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quantile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m                                    \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finaltr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finaltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcurScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_finalval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_finalval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcurScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n\u001b[1;32m    797\u001b[0m                                              \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                                              self.learning_rate, k=k)\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m# add tree to ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mupdate_terminal_regions\u001b[0;34m(self, tree, X, y, residual, y_pred, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[1;32m    247\u001b[0m             self._update_terminal_region(tree, masked_terminal_regions,\n\u001b[1;32m    248\u001b[0m                                          \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                          y_pred[:, k], sample_weight)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# update predictions (both in-bag and out-of-bag)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mc:\\users\\srryi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_update_terminal_region\u001b[0;34m(self, tree, terminal_regions, leaf, X, y, residual, pred, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m                                 residual, pred, sample_weight):\n\u001b[1;32m    436\u001b[0m         \u001b[0mterminal_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_regions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         diff = (y.take(terminal_region, axis=0)\n\u001b[0m\u001b[1;32m    438\u001b[0m                 - pred.take(terminal_region, axis=0))\n\u001b[1;32m    439\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminal_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SjSHhYKSTZF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosted Regressor"
      ]
    },
    {
      "metadata": {
        "id": "vgzUggUGLm1K",
        "colab_type": "code",
        "colab": {},
        "outputId": "8305d6b1-1d30-46bd-90eb-81b14f24d953"
      },
      "cell_type": "code",
      "source": [
        "GBR = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                            subsample=.99,alpha=.89)\n",
        "GBR.fit(X_finaltr, y_finaltr.squeeze())\n",
        "GBR.score(X_finalval, y_finalval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7901517153918347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "metadata": {
        "id": "y7XJ4aMxLm1W",
        "colab_type": "code",
        "colab": {},
        "outputId": "63a267c9-8b56-42b1-e337-e5887d602a9d"
      },
      "cell_type": "code",
      "source": [
        "GBRnSV = GradientBoostingRegressor(n_estimators = 2000, loss='quantile', learning_rate=.014, max_depth=2,\\\n",
        "                                    subsample=.99,alpha=.89)\n",
        "GBRnSV.fit(X_nSVtr, y_nSVtr)\n",
        "\n",
        "GBRnSV.score(X_nSVval, y_nSVval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36443930091932547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "v2RH2EauLm1Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a9098d5-bc9d-4532-d585-e71e545e7bf9"
      },
      "cell_type": "code",
      "source": [
        "GBR.score(X_finalval, y_finalval.squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7901517153918347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "metadata": {
        "id": "qH7kdLUbT3EZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"MSE with street view:\" + \"    \" + str(mse(y_finalval.squeeze(), GBR.predict(X_finalval))))\n",
        "print(\"MSE without street view: \" + str(mse(y_nSVval.squeeze(), GBRnSV.predict(X_nSVval))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9d9dyNLoUkJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Calculate the average percent error \"\"\"\n",
        "pErrorWo = abs((GBRnSV.predict(X_nSVtest) - y_nSVtest.squeeze())) / y_nSVtest.squeeze()\n",
        "print(\"Without street view mean: \" + str(statistics.mean(pErrorWo).round(4) * 100) + \"%\")\n",
        "print(\"Without street view median: \" + str(statistics.median(pErrorWo).round(4) * 100) + \"%\\n\")\n",
        "\n",
        "pError = abs((GBR.predict(X_Ftest) - y_Ftest.squeeze())) / y_Ftest.squeeze()\n",
        "print(\"With street view mean: \" + str(statistics.mean(pError).round(4) * 100) + \"%\")\n",
        "print(\"With street view median: \" + str(statistics.median(pError).round(4) * 100) + \"%\\n\")\n",
        "\n",
        "print(\"No street view accuracy: \" + str(GBRnSV.score(X_nSVtest, y_nSVtest.squeeze())))\n",
        "print(\"With street view accuracy: \" + str(GBR.score(X_Ftest, y_Ftest.squeeze())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9EYJnp0UHAy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_finalval.squeeze(), GBR.predict(X_finalval))\n",
        "plt.show()\n",
        "plt.scatter(y_nSVval.squeeze(), GBRnSV.predict(X_nSVval))\n",
        "plt.show()\n",
        "plt.scatter(y_finalval.squeeze(), GBR.predict(X_finalval))\n",
        "plt.scatter(y_nSVval.squeeze(), GBRnSV.predict(X_nSVval))\n",
        "plt.ylim(ymax=5000000, ymin=0)\n",
        "plt.xlim(xmax = 5000000, xmin=0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3SBYoxsQamw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below we run Kruskal-Wallis H-Test to further analyze our model's output. We compare our predicted values and the true values to determine if they achieved similar population medians. The predicted values and the true values for both models, with Street View and without Streeet View, differ significantly with p-values smaller than 0.0001. However, the population medians of our predictions from the model with Street View and without Street View do not significantly differ."
      ]
    },
    {
      "metadata": {
        "id": "fY_58iBcLm1g",
        "colab_type": "code",
        "colab": {},
        "outputId": "978bc095-f939-4e9b-96ae-54df9ee8e87c"
      },
      "cell_type": "code",
      "source": [
        "print(scipy.stats.kruskal(GBRnSV.predict(X_nSVtest), y_nSVtest))\n",
        "print(scipy.stats.kruskal(GBR.predict(X_finaltest),y_finaltest))\n",
        "print(scipy.stats.kruskal(GBR.predict(X_finaltest),GBRnSV.predict(X_nSVtest)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KruskalResult(statistic=94.59606977209059, pvalue=2.3348143801153684e-22)\n",
            "KruskalResult(statistic=98.20801470522338, pvalue=3.7666239843010957e-23)\n",
            "KruskalResult(statistic=0.031638759587793386, pvalue=0.8588228138954208)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-fGlMhrLm1j",
        "colab_type": "code",
        "colab": {},
        "outputId": "42ceb60b-3d37-4e89-ee39-aa5c85ff298c"
      },
      "cell_type": "code",
      "source": [
        "scipy.stats.kruskal((GBRnSV.predict(X_nSVtest), y_nSVtest),(y_finaltest,y_finaltest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KruskalResult(statistic=876810.1861107722, pvalue=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    }
  ]
}